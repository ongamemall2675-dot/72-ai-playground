# -*- coding: utf-8 -*-
"""
AI ì´ë¯¸ì§€ ìƒì„±ê¸° v2.5 - ë¯¸ë“œì €ë‹ˆ ìŠ¤íƒ€ì¼ í”„ë¡¬í”„íŠ¸ + í™•ì¥ ë””ìì´ë„ˆ + Vertex AI
72ë†€ì´í„° ë…ë¦½ ëª¨ë“ˆ
"""

import os
import json
import asyncio
import httpx
from datetime import datetime
from typing import Optional, List, Dict, Any
from pathlib import Path
from fastapi import FastAPI, HTTPException, UploadFile, File
from fastapi.responses import HTMLResponse, JSONResponse, FileResponse
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel

# ============================================
# App Setup
# ============================================
app = FastAPI(title="AI ì´ë¯¸ì§€ ìƒì„±ê¸°", version="2.6.0")

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ê²½ë¡œ ì„¤ì •
BASE_DIR = Path(__file__).parent
DATA_DIR = BASE_DIR / "data"
TEMPLATES_DIR = BASE_DIR / "templates"
DATA_DIR.mkdir(exist_ok=True)
TEMPLATES_DIR.mkdir(exist_ok=True)

# ============================================
# ëŸ°íƒ€ì„ ì„¤ì • (API í‚¤ ë“±)
# ============================================
runtime_settings = {
    "api_keys": {
        "openai": "",
        "replicate": "",
        "gemini": "",
        "claude": "",
        "vertex": ""
    },
    "default_provider": "dalle3"
}

def load_api_keys():
    """api_secrets.jsonì—ì„œ í‚¤ ë¡œë“œ"""
    secrets_path = BASE_DIR / "api_secrets.json"
    if secrets_path.exists():
        with open(secrets_path, 'r', encoding='utf-8') as f:
            secrets = json.load(f)
            runtime_settings["api_keys"]["openai"] = secrets.get("openai_api_key", "")
            runtime_settings["api_keys"]["replicate"] = secrets.get("replicate_api_token", "") or secrets.get("flux_api_key", "")
            runtime_settings["api_keys"]["gemini"] = secrets.get("gemini_api_key", "")
            runtime_settings["api_keys"]["claude"] = secrets.get("claude_api_key", "")
            runtime_settings["api_keys"]["vertex"] = secrets.get("vertex_api_key", "") or secrets.get("google_cloud_key", "")

load_api_keys()

# ============================================
# ì¹´í…Œê³ ë¦¬ ê·¸ë£¹ ì •ì˜
# ============================================
CATEGORY_GROUPS = {
    "video": {
        "name": "ğŸ¬ ì˜ìƒ",
        "description": "ì˜ìƒ ì œì‘ì— ìµœì í™”ëœ ìŠ¤íƒ€ì¼",
        "categories": ["video", "vlog", "news", "education", "entertainment"]
    },
    "art": {
        "name": "ğŸ¨ ì•„íŠ¸",
        "description": "ì˜ˆìˆ ì  í‘œí˜„ ìŠ¤íƒ€ì¼",
        "categories": ["art"]
    },
    "cartoon": {
        "name": "ğŸ“š ë§Œí™”",
        "description": "ë§Œí™”/ì• ë‹ˆë©”ì´ì…˜ ìŠ¤íƒ€ì¼",
        "categories": ["webtoon", "anime", "cartoon", "comic", "simple"]
    },
    "photo": {
        "name": "ğŸ“· ì‹¤ì‚¬",
        "description": "ì‚¬ì§„ê°™ì€ ì‹¤ì‚¬ ìŠ¤íƒ€ì¼",
        "categories": ["photo", "realestate", "food", "tech"]
    },
    "design": {
        "name": "ğŸ“ ë””ìì¸",
        "description": "ê·¸ë˜í”½ ë””ìì¸ ìŠ¤íƒ€ì¼",
        "categories": ["design"]
    },
    "special": {
        "name": "âœ¨ íŠ¹ìˆ˜",
        "description": "íŠ¹ìˆ˜ íš¨ê³¼ ìŠ¤íƒ€ì¼",
        "categories": ["scifi", "fantasy", "retro"]
    }
}

# ì¦ê²¨ì°¾ê¸° ì €ì¥/ë¡œë“œ
def get_favorites() -> List[str]:
    """ì¦ê²¨ì°¾ê¸° ë””ìì´ë„ˆ ID ëª©ë¡ ë°˜í™˜"""
    path = DATA_DIR / "favorites.json"
    if path.exists():
        with open(path, 'r', encoding='utf-8') as f:
            return json.load(f)
    return []

def save_favorites(favorites: List[str]):
    """ì¦ê²¨ì°¾ê¸° ì €ì¥"""
    path = DATA_DIR / "favorites.json"
    with open(path, 'w', encoding='utf-8') as f:
        json.dump(favorites, f, ensure_ascii=False, indent=2)

def add_favorite(designer_id: str) -> bool:
    """ì¦ê²¨ì°¾ê¸° ì¶”ê°€"""
    favorites = get_favorites()
    if designer_id not in favorites:
        favorites.append(designer_id)
        save_favorites(favorites)
        return True
    return False

def remove_favorite(designer_id: str) -> bool:
    """ì¦ê²¨ì°¾ê¸° ì œê±°"""
    favorites = get_favorites()
    if designer_id in favorites:
        favorites.remove(designer_id)
        save_favorites(favorites)
        return True
    return False

# ============================================
# í™•ì¥ í”„ë¦¬ì…‹ ë””ìì´ë„ˆ (20ì¢… ì´ìƒ)
# ============================================
PRESET_DESIGNERS = {
    # ì˜ìƒ ìŠ¤íƒ€ì¼
    "cinematic_pro": {
        "id": "cinematic_pro",
        "name": "ğŸ¬ ì‹œë„¤ë§ˆí‹± í”„ë¡œ",
        "description": "ì˜í™” ê°™ì€ ë“œë¼ë§ˆí‹±í•œ ìŠ¤íƒ€ì¼",
        "category": "video",
        "is_preset": True,
        "prompt_prefix": "[cinematic lighting, dramatic atmosphere, film grain] ",
        "prompt_suffix": " --style cinematic --quality 4K --ar 16:9",
        "negative_prompt": "cartoon, anime, low quality, blurry, distorted",
        "best_for": ["ë‹¤í", "ìŠ¤í† ë¦¬í…”ë§", "ë“œë¼ë§ˆ"]
    },
    "bright_cheerful": {
        "id": "bright_cheerful",
        "name": "â˜€ï¸ ë°ê³  ì¹œê·¼",
        "description": "ë”°ëœ»í•˜ê³  ì ‘ê·¼í•˜ê¸° ì‰¬ìš´ ìŠ¤íƒ€ì¼",
        "category": "vlog",
        "is_preset": True,
        "prompt_prefix": "[bright natural lighting, cheerful atmosphere] ",
        "prompt_suffix": " --style friendly --quality HD",
        "negative_prompt": "dark, scary, gloomy, horror, sad",
        "best_for": ["ë¸Œì´ë¡œê·¸", "ì¼ìƒ", "ë¼ì´í”„ìŠ¤íƒ€ì¼"]
    },
    "tech_modern": {
        "id": "tech_modern",
        "name": "ğŸ–¥ï¸ í…Œí¬ ëª¨ë˜",
        "description": "ê¹”ë”í•œ ê¸°ìˆ /IT ìŠ¤íƒ€ì¼",
        "category": "tech",
        "is_preset": True,
        "prompt_prefix": "[modern tech aesthetic, clean lines, minimalist] ",
        "prompt_suffix": " --style futuristic --quality 4K",
        "negative_prompt": "vintage, old, rustic, messy, cluttered",
        "best_for": ["IT", "ë¦¬ë·°", "í…Œí¬"]
    },
    "gaming": {
        "id": "gaming",
        "name": "ğŸ® ê²Œì´ë¨¸ ìŠ¤íƒ€ì¼",
        "description": "ê²Œì„/ì—”í„°í…Œì¸ë¨¼íŠ¸ ìŠ¤íƒ€ì¼",
        "category": "entertainment",
        "is_preset": True,
        "prompt_prefix": "[gaming aesthetic, neon lights, RGB colors, dynamic action] ",
        "prompt_suffix": " --style esports --quality HD --vivid",
        "negative_prompt": "boring, plain, muted colors, static",
        "best_for": ["ê²Œì„", "eìŠ¤í¬ì¸ ", "ì—”í„°í…Œì¸ë¨¼íŠ¸"]
    },
    "education_clean": {
        "id": "education_clean",
        "name": "ğŸ“š êµìœ¡ í´ë¦°",
        "description": "ê¹”ë”í•˜ê³  ì§‘ì¤‘í•˜ê¸° ì¢‹ì€ ìŠ¤íƒ€ì¼",
        "category": "education",
        "is_preset": True,
        "prompt_prefix": "[clean educational style, simple background, clear focus] ",
        "prompt_suffix": " --style informative --quality HD",
        "negative_prompt": "distracting, busy background, cluttered, confusing",
        "best_for": ["ê°•ì˜", "íŠœí† ë¦¬ì–¼", "ì„¤ëª…"]
    },
    "food_photography": {
        "id": "food_photography",
        "name": "ğŸ³ í‘¸ë“œ ë§›ìˆê²Œ",
        "description": "ìŒì‹ì´ ë§›ìˆì–´ ë³´ì´ëŠ” ìŠ¤íƒ€ì¼",
        "category": "food",
        "is_preset": True,
        "prompt_prefix": "[food photography, appetizing, warm lighting] ",
        "prompt_suffix": " --style delicious --quality 4K --bokeh",
        "negative_prompt": "unappetizing, cold, bland, poorly lit",
        "best_for": ["ë¨¹ë°©", "ìš”ë¦¬", "ë ˆì‹œí”¼"]
    },
    "realestate_pro": {
        "id": "realestate_pro",
        "name": "ğŸ  ë¶€ë™ì‚° í”„ë¡œ",
        "description": "ì „ë¬¸ì ì¸ ë¶€ë™ì‚° ìŠ¤íƒ€ì¼",
        "category": "realestate",
        "is_preset": True,
        "prompt_prefix": "[professional real estate photography, warm natural lighting] ",
        "prompt_suffix": " --style architectural --quality 4K --wide",
        "negative_prompt": "dark, cramped, messy, low quality, distorted",
        "best_for": ["ë¶€ë™ì‚°", "ì¸í…Œë¦¬ì–´", "ê±´ì¶•"]
    },
    "news_info": {
        "id": "news_info",
        "name": "ğŸ“° ë‰´ìŠ¤/ì •ë³´",
        "description": "ì‹ ë¢°ê° ìˆëŠ” ì •ë³´ ì „ë‹¬ ìŠ¤íƒ€ì¼",
        "category": "news",
        "is_preset": True,
        "prompt_prefix": "[news broadcast style, professional, trustworthy] ",
        "prompt_suffix": " --style broadcast --quality HD",
        "negative_prompt": "unprofessional, chaotic, unreliable looking",
        "best_for": ["ì •ë³´", "ë‰´ìŠ¤", "ë¶„ì„"]
    },
    
    # ë§Œí™”/ì• ë‹ˆë©”ì´ì…˜ ìŠ¤íƒ€ì¼
    "webtoon_korean": {
        "id": "webtoon_korean",
        "name": "ğŸ‡°ğŸ‡· í•œêµ­ ì›¹íˆ°",
        "description": "í•œêµ­ ì›¹íˆ° ìŠ¤íƒ€ì¼",
        "category": "webtoon",
        "is_preset": True,
        "prompt_prefix": "[Korean webtoon style, manhwa art, clean line art, vibrant colors] ",
        "prompt_suffix": " --style webtoon --quality HD --niji 6",
        "negative_prompt": "3D, realistic, photograph, blurry",
        "best_for": ["ì›¹íˆ°", "ë§Œí™”", "ìŠ¤í† ë¦¬"]
    },
    "webtoon_japanese": {
        "id": "webtoon_japanese",
        "name": "ğŸ‡¯ğŸ‡µ ì¼ë³¸ ë§Œí™”",
        "description": "ì¼ë³¸ ë§Œí™”/ì• ë‹ˆë©”ì´ì…˜ ìŠ¤íƒ€ì¼",
        "category": "anime",
        "is_preset": True,
        "prompt_prefix": "[Japanese manga style, anime art, detailed shading] ",
        "prompt_suffix": " --style anime --niji 6 --quality HD",
        "negative_prompt": "realistic, photograph, 3D render",
        "best_for": ["ì• ë‹ˆë©”ì´ì…˜", "ë§Œí™”", "ì¼ëŸ¬ìŠ¤íŠ¸"]
    },
    "stickman": {
        "id": "stickman",
        "name": "ğŸ§ ìŠ¤í‹±ë§¨",
        "description": "ì‹¬í”Œí•œ ë§‰ëŒ€ ì¸í˜• ìŠ¤íƒ€ì¼",
        "category": "simple",
        "is_preset": True,
        "prompt_prefix": "[simple stick figure drawing, minimal art, black and white] ",
        "prompt_suffix": " --style minimalist --simple",
        "negative_prompt": "detailed, realistic, colorful, complex",
        "best_for": ["ì„¤ëª…", "êµìœ¡", "ê°œë…ë„"]
    },
    "cartoon_disney": {
        "id": "cartoon_disney",
        "name": "ğŸ° ë””ì¦ˆë‹ˆ ì¹´íˆ°",
        "description": "ë””ì¦ˆë‹ˆ/í”½ì‚¬ ìŠ¤íƒ€ì¼ 3D ì¹´íˆ°",
        "category": "cartoon",
        "is_preset": True,
        "prompt_prefix": "[Disney Pixar style, 3D cartoon, expressive characters] ",
        "prompt_suffix": " --style disney --quality 4K --render 3D",
        "negative_prompt": "realistic, dark, scary, horror",
        "best_for": ["ì• ë‹ˆë©”ì´ì…˜", "í‚¤ì¦ˆ", "ê°€ì¡±"]
    },
    "comic_marvel": {
        "id": "comic_marvel",
        "name": "ğŸ¦¸ ë§ˆë¸” ì½”ë¯¹ìŠ¤",
        "description": "ë¯¸êµ­ ì½”ë¯¹ë¶ ìŠ¤íƒ€ì¼",
        "category": "comic",
        "is_preset": True,
        "prompt_prefix": "[American comic book style, bold colors, dynamic poses, halftone dots] ",
        "prompt_suffix": " --style comic --quality HD --bold",
        "negative_prompt": "photograph, realistic, anime, soft",
        "best_for": ["íˆì–´ë¡œ", "ì•¡ì…˜", "ìŠ¤í† ë¦¬"]
    },
    
    # ì•„íŠ¸ ìŠ¤íƒ€ì¼
    "watercolor": {
        "id": "watercolor",
        "name": "ğŸ¨ ìˆ˜ì±„í™”",
        "description": "ë¶€ë“œëŸ¬ìš´ ìˆ˜ì±„í™” ìŠ¤íƒ€ì¼",
        "category": "art",
        "is_preset": True,
        "prompt_prefix": "[watercolor painting, soft colors, artistic brushstrokes] ",
        "prompt_suffix": " --style watercolor --artistic",
        "negative_prompt": "digital, harsh, sharp lines, photograph",
        "best_for": ["ê°ì„±", "ì•„íŠ¸", "íë§"]
    },
    "oil_painting": {
        "id": "oil_painting",
        "name": "ğŸ–¼ï¸ ìœ í™”",
        "description": "í´ë˜ì‹ ìœ í™” ìŠ¤íƒ€ì¼",
        "category": "art",
        "is_preset": True,
        "prompt_prefix": "[oil painting style, classical art, rich textures, masterpiece] ",
        "prompt_suffix": " --style painting --artistic --museum",
        "negative_prompt": "digital, modern, cartoon, photograph",
        "best_for": ["í´ë˜ì‹", "ì•„íŠ¸", "ê³ ê¸‰"]
    },
    "sketch_pencil": {
        "id": "sketch_pencil",
        "name": "âœï¸ ì—°í•„ ìŠ¤ì¼€ì¹˜",
        "description": "ì—°í•„ ë“œë¡œì‰ ìŠ¤íƒ€ì¼",
        "category": "art",
        "is_preset": True,
        "prompt_prefix": "[pencil sketch, hand-drawn, detailed line work] ",
        "prompt_suffix": " --style sketch --monochrome",
        "negative_prompt": "color, digital, photograph, painting",
        "best_for": ["ì½˜ì…‰íŠ¸", "ë“œë¡œì‰", "ìŠ¤ì¼€ì¹˜"]
    },
    "pop_art": {
        "id": "pop_art",
        "name": "ğŸ† íŒì•„íŠ¸",
        "description": "ì•¤ë”” ì›Œí™€ ìŠ¤íƒ€ì¼ íŒì•„íŠ¸",
        "category": "art",
        "is_preset": True,
        "prompt_prefix": "[pop art style, bold colors, Andy Warhol inspired, retro] ",
        "prompt_suffix": " --style popart --vivid --retro",
        "negative_prompt": "realistic, photograph, muted colors",
        "best_for": ["ë ˆíŠ¸ë¡œ", "ì•„íŠ¸", "ë””ìì¸"]
    },
    
    # ì‚¬ì§„/ì‹¤ì‚¬ ìŠ¤íƒ€ì¼
    "photo_portrait": {
        "id": "photo_portrait",
        "name": "ğŸ“¸ ì¸ë¬¼ ì‚¬ì§„",
        "description": "í”„ë¡œí˜ì…”ë„ ì¸ë¬¼ ì‚¬ì§„",
        "category": "photo",
        "is_preset": True,
        "prompt_prefix": "[professional portrait photography, studio lighting, sharp focus] ",
        "prompt_suffix": " --style portrait --quality 4K --bokeh",
        "negative_prompt": "cartoon, anime, blurry, distorted",
        "best_for": ["ì¸ë¬¼", "í”„ë¡œí•„", "ì´ˆìƒ"]
    },
    "photo_landscape": {
        "id": "photo_landscape",
        "name": "ğŸ”ï¸ í’ê²½ ì‚¬ì§„",
        "description": "ì•„ë¦„ë‹¤ìš´ í’ê²½ ì‚¬ì§„",
        "category": "photo",
        "is_preset": True,
        "prompt_prefix": "[landscape photography, golden hour, stunning scenery] ",
        "prompt_suffix": " --style landscape --quality 4K --wide",
        "negative_prompt": "urban, indoor, people, artificial",
        "best_for": ["í’ê²½", "ì—¬í–‰", "ìì—°"]
    },
    "photo_product": {
        "id": "photo_product",
        "name": "ğŸ“¦ ì œí’ˆ ì‚¬ì§„",
        "description": "ì œí’ˆ ì´¬ì˜ ìŠ¤íƒ€ì¼",
        "category": "photo",
        "is_preset": True,
        "prompt_prefix": "[product photography, clean white background, professional lighting] ",
        "prompt_suffix": " --style product --quality 4K --sharp",
        "negative_prompt": "messy, dark, cluttered, busy background",
        "best_for": ["ì œí’ˆ", "ê´‘ê³ ", "ì»¤ë¨¸ìŠ¤"]
    },
    
    # íŠ¹ìˆ˜ ìŠ¤íƒ€ì¼
    "cyberpunk": {
        "id": "cyberpunk",
        "name": "ğŸŒƒ ì‚¬ì´ë²„í‘í¬",
        "description": "ë„¤ì˜¨ ì‚¬ì´ë²„í‘í¬ ìŠ¤íƒ€ì¼",
        "category": "scifi",
        "is_preset": True,
        "prompt_prefix": "[cyberpunk aesthetic, neon lights, futuristic city, rain] ",
        "prompt_suffix": " --style cyberpunk --neon --dark",
        "negative_prompt": "bright daylight, nature, rural, vintage",
        "best_for": ["SF", "ë¯¸ë˜", "í…Œí¬"]
    },
    "fantasy_epic": {
        "id": "fantasy_epic",
        "name": "ğŸ‰ íŒíƒ€ì§€ ì—í”½",
        "description": "ì¥ëŒ€í•œ íŒíƒ€ì§€ ìŠ¤íƒ€ì¼",
        "category": "fantasy",
        "is_preset": True,
        "prompt_prefix": "[epic fantasy art, dramatic lighting, magical atmosphere] ",
        "prompt_suffix": " --style fantasy --epic --quality 4K",
        "negative_prompt": "modern, urban, technology, mundane",
        "best_for": ["íŒíƒ€ì§€", "ê²Œì„", "ìŠ¤í† ë¦¬"]
    },
    "vintage_retro": {
        "id": "vintage_retro",
        "name": "ğŸ“¼ ë¹ˆí‹°ì§€ ë ˆíŠ¸ë¡œ",
        "description": "80-90ë…„ëŒ€ ë ˆíŠ¸ë¡œ ìŠ¤íƒ€ì¼",
        "category": "retro",
        "is_preset": True,
        "prompt_prefix": "[retro vintage style, 80s aesthetic, VHS effect, nostalgic] ",
        "prompt_suffix": " --style retro --vintage --grain",
        "negative_prompt": "modern, clean, digital, futuristic",
        "best_for": ["ë ˆíŠ¸ë¡œ", "ë³µê³ ", "ê°ì„±"]
    },
    "isometric_3d": {
        "id": "isometric_3d",
        "name": "ğŸ§Š ì•„ì´ì†Œë©”íŠ¸ë¦­ 3D",
        "description": "ì•„ì´ì†Œë©”íŠ¸ë¦­ ë·° 3D ì¼ëŸ¬ìŠ¤íŠ¸",
        "category": "design",
        "is_preset": True,
        "prompt_prefix": "[isometric 3D illustration, clean design, geometric shapes] ",
        "prompt_suffix": " --style isometric --3D --clean",
        "negative_prompt": "realistic, photograph, organic, messy",
        "best_for": ["ì¸í¬ê·¸ë˜í”½", "ë””ìì¸", "ì„¤ëª…"]
    },
    "flat_design": {
        "id": "flat_design",
        "name": "ğŸ“ í”Œë« ë””ìì¸",
        "description": "ë¯¸ë‹ˆë©€ í”Œë« ë””ìì¸",
        "category": "design",
        "is_preset": True,
        "prompt_prefix": "[flat design, minimal illustration, simple shapes, bold colors] ",
        "prompt_suffix": " --style flat --minimal --vector",
        "negative_prompt": "3D, realistic, complex, detailed, photograph",
        "best_for": ["UI", "ì•„ì´ì½˜", "ì¸í¬ê·¸ë˜í”½"]
    },
    "lowpoly": {
        "id": "lowpoly",
        "name": "ğŸ’ ë¡œìš°í´ë¦¬",
        "description": "ë¡œìš°í´ë¦¬ê³¤ 3D ìŠ¤íƒ€ì¼",
        "category": "design",
        "is_preset": True,
        "prompt_prefix": "[low poly art, geometric, triangular shapes, 3D render] ",
        "prompt_suffix": " --style lowpoly --3D --geometric",
        "negative_prompt": "realistic, smooth, organic, photograph",
        "best_for": ["ê²Œì„", "3D", "ëª¨ë˜"]
    },
    "pixel_art": {
        "id": "pixel_art",
        "name": "ğŸ‘¾ í”½ì…€ ì•„íŠ¸",
        "description": "ë ˆíŠ¸ë¡œ ê²Œì„ í”½ì…€ ì•„íŠ¸",
        "category": "retro",
        "is_preset": True,
        "prompt_prefix": "[pixel art, retro game style, 8-bit, 16-bit] ",
        "prompt_suffix": " --style pixel --retro --8bit",
        "negative_prompt": "realistic, smooth, high resolution, photograph",
        "best_for": ["ê²Œì„", "ë ˆíŠ¸ë¡œ", "ë…¸ìŠ¤íƒ¤ì§€ì•„"]
    }
}

# ê°ì • â†’ ì˜ë¬¸ ë§¤í•‘
EMOTION_MAP = {
    "neutral": "calm and balanced mood",
    "curious": "intriguing and curious atmosphere",
    "happy": "joyful and happy mood",
    "sad": "melancholic and emotional",
    "excited": "energetic and exciting",
    "serious": "serious and professional",
    "warm": "warm and cozy feeling",
    "dramatic": "dramatic and intense",
    "surprise": "surprising and shocking",
    "fear": "tense and suspenseful",
    "anger": "intense and powerful",
    "love": "romantic and tender"
}

# ============================================
# Pydantic Models
# ============================================
class M06SceneImport(BaseModel):
    project_id: Optional[str] = None
    title: Optional[str] = None
    scenes: List[Dict[str, Any]]
    thumbnail_suggestions: Optional[List[Dict]] = None

class PromptGenerateRequest(BaseModel):
    scenes: List[Dict[str, Any]]
    designer_id: str = "bright_cheerful"

class ImageGenerateRequest(BaseModel):
    prompt_en: str
    negative_prompt: Optional[str] = ""
    provider: str = "dalle3"
    size: str = "1792x1024"

class BatchGenerateRequest(BaseModel):
    prompts: List[Dict[str, Any]]
    provider: str = "dalle3"
    designer_id: Optional[str] = None

class CustomDesigner(BaseModel):
    name: str
    description: str
    category: str = "custom"
    prompt_prefix: str
    prompt_suffix: str
    negative_prompt: str = ""
    best_for: List[str] = []

class ApiKeyTest(BaseModel):
    provider: str
    api_key: str

class KoToEnRequest(BaseModel):
    korean_description: Optional[str] = None
    korean_text: Optional[str] = None  # í”„ë¡ íŠ¸ì—”ë“œ í˜¸í™˜ìš©
    designer_id: str = "bright_cheerful"
    ai_provider: str = "gemini"

class RecommendDesignerRequest(BaseModel):
    description: str = ""
    scenes: Optional[List[Dict[str, Any]]] = None  # ëŒ€ë³¸ ë¶„ì„ìš© ì¥ë©´ ë°ì´í„°
    ai_provider: str = "gemini"

# ============================================
# ë””ìì´ë„ˆ ê´€ë¦¬ í•¨ìˆ˜
# ============================================
def get_custom_designers() -> Dict:
    path = DATA_DIR / "designers.json"
    if path.exists():
        with open(path, 'r', encoding='utf-8') as f:
            return json.load(f)
    return {}

def save_custom_designers(designers: Dict):
    path = DATA_DIR / "designers.json"
    with open(path, 'w', encoding='utf-8') as f:
        json.dump(designers, f, ensure_ascii=False, indent=2)

def get_all_designers() -> Dict:
    custom = get_custom_designers()
    return {**PRESET_DESIGNERS, **custom}

def get_designer(designer_id: str) -> Optional[Dict]:
    return get_all_designers().get(designer_id)

# ============================================
# í”„ë¡¬í”„íŠ¸ ìƒì„± í•¨ìˆ˜ (ë¯¸ë“œì €ë‹ˆ ìŠ¤íƒ€ì¼)
# ============================================
def build_midjourney_prompt(scene: Dict, designer: Dict) -> Dict:
    """ë¯¸ë“œì €ë‹ˆ ìŠ¤íƒ€ì¼ [íš¨ê³¼] í”„ë¡¬í”„íŠ¸ í˜•ì‹ìœ¼ë¡œ ìƒì„±"""
    script_text = scene.get("script_text", "")
    keywords = scene.get("keywords", [])
    emotion = scene.get("emotion", "neutral")
    
    keyword_str = ", ".join(keywords) if keywords else ""
    emotion_str = EMOTION_MAP.get(emotion, "neutral mood")
    
    # ë¯¸ë“œì €ë‹ˆ ìŠ¤íƒ€ì¼ í”„ë¡¬í”„íŠ¸ êµ¬ì„±
    prefix = designer.get("prompt_prefix", "")
    suffix = designer.get("prompt_suffix", "")
    
    # [íš¨ê³¼] ë‚´ìš© í˜•ì‹
    main_content = f"{keyword_str}, {emotion_str}" if keyword_str else emotion_str
    prompt_en = f"{prefix}{main_content}{suffix}"
    
    # í•œê¸€ ì„¤ëª… ìƒì„±
    prompt_ko = f"[{emotion}] {script_text[:80]}..." if len(script_text) > 80 else f"[{emotion}] {script_text}"
    
    return {
        "scene_id": scene.get("scene_id", 0),
        "script_text": script_text,
        "prompt_en": prompt_en.strip(),
        "prompt_ko": prompt_ko,
        "negative_prompt": designer.get("negative_prompt", ""),
        "keywords": keywords,
        "emotion": emotion,
        "status": "ready"
    }

async def translate_ko_to_en_prompt(korean_desc: str, designer: Dict, provider: str = "gemini") -> str:
    """í•œê¸€ ì´ë¯¸ì§€ ì„¤ëª…ì„ ì˜ë¬¸ í”„ë¡¬í”„íŠ¸ë¡œ ë³€í™˜ (ë™ê¸°í™”ìš©)
    
    ì¤‘ìš”: ë°˜í™˜ë˜ëŠ” í”„ë¡¬í”„íŠ¸ëŠ” ë°˜ë“œì‹œ ì˜ì–´ë¡œë§Œ ì‘ì„±ë¨
    """
    system_prompt = f"""You are an expert AI image prompt generator.
Convert Korean image description to English Midjourney-style prompt.
Designer style: {designer.get('name', 'default')}

IMPORTANT RULES:
1. OUTPUT MUST BE IN ENGLISH ONLY - NO KOREAN CHARACTERS
2. Use format: [effects] detailed visual description --style parameters
3. Focus on visual elements: lighting, composition, mood, colors, subjects
4. The description is about what the IMAGE should look like, not the script content

Keep the artistic intent and mood, but translate all concepts to English."""

    user_prompt = f"""Korean image description: "{korean_desc}"

Convert to English-only Midjourney prompt.
RETURN ONLY THE ENGLISH PROMPT, no explanation, no Korean text."""

    try:
        if provider == "gemini" and runtime_settings["api_keys"]["gemini"]:
            import google.generativeai as genai
            genai.configure(api_key=runtime_settings["api_keys"]["gemini"])
            model = genai.GenerativeModel("gemini-2.0-flash")
            response = model.generate_content(f"{system_prompt}\n\n{user_prompt}")
            result = response.text.strip()
            # í•œê¸€ ë¬¸ìê°€ í¬í•¨ë˜ì–´ ìˆìœ¼ë©´ ì œê±°ëœ ë²„ì „ ë°˜í™˜
            import re
            if re.search('[ê°€-í£]', result):
                # í•œê¸€ì´ í¬í•¨ë˜ì–´ ìˆìœ¼ë©´ ì˜ì–´ë§Œ ì¶”ì¶œ
                result = re.sub('[ê°€-í£]+', '', result).strip()
            return result
            
        elif provider in ["openai", "gpt4o_mini"] and runtime_settings["api_keys"]["openai"]:
            model_name = "gpt-4o-mini" if provider == "gpt4o_mini" else "gpt-4o"
            async with httpx.AsyncClient() as client:
                response = await client.post(
                    "https://api.openai.com/v1/chat/completions",
                    headers={"Authorization": f"Bearer {runtime_settings['api_keys']['openai']}"},
                    json={
                        "model": model_name,
                        "messages": [
                            {"role": "system", "content": system_prompt},
                            {"role": "user", "content": user_prompt}
                        ],
                        "max_tokens": 500
                    },
                    timeout=30
                )
                data = response.json()
                result = data["choices"][0]["message"]["content"].strip()
                import re
                if re.search('[ê°€-í£]', result):
                    result = re.sub('[ê°€-í£]+', '', result).strip()
                return result
                
        elif provider == "claude" and runtime_settings["api_keys"]["claude"]:
            async with httpx.AsyncClient() as client:
                response = await client.post(
                    "https://api.anthropic.com/v1/messages",
                    headers={
                        "x-api-key": runtime_settings["api_keys"]["claude"],
                        "anthropic-version": "2023-06-01",
                        "content-type": "application/json"
                    },
                    json={
                        "model": "claude-sonnet-4-20250514",
                        "max_tokens": 500,
                        "messages": [{"role": "user", "content": f"{system_prompt}\n\n{user_prompt}"}]
                    },
                    timeout=30
                )
                data = response.json()
                result = data["content"][0]["text"].strip()
                import re
                if re.search('[ê°€-í£]', result):
                    result = re.sub('[ê°€-í£]+', '', result).strip()
                return result
    except Exception as e:
        return f"Error: {str(e)}"
    
    # ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ ì˜ë¬¸ í”„ë¡¬í”„íŠ¸ ë°˜í™˜
    return "visual scene, professional quality"

async def generate_prompt_with_ai(scene: Dict, designer: Dict, provider: str = "gemini") -> Dict:
    """AIë¥¼ ì‚¬ìš©í•´ êµ¬ì¡°í™”ëœ íƒœê·¸ í˜•ì‹ í”„ë¡¬í”„íŠ¸ ìƒì„±
    
    ì¶œë ¥ í˜•ì‹:
    - PROMPT_EN: ì˜ì–´ë¡œë§Œ ì‘ì„±ëœ ì´ë¯¸ì§€ ìƒì„± í”„ë¡¬í”„íŠ¸ (í•œê¸€ ë¶ˆí¬í•¨)
    - PROMPT_KO: ì´ë¯¸ì§€ ë‚´ìš©ì— ëŒ€í•œ í•œê¸€ ì„¤ëª… (ëŒ€ë³¸ì´ ì•„ë‹Œ ì´ë¯¸ì§€ ë¬˜ì‚¬)
    
    [Style Tag] [Context Tag] Core Description [Visual Details] --parameters
    """
    script_text = scene.get("script_text", "")
    keywords = scene.get("keywords", [])
    emotion = scene.get("emotion", "neutral")
    
    # ë””ìì´ë„ˆ ìŠ¤íƒ€ì¼ ì •ë³´
    designer_name = designer.get('name', 'default')
    designer_desc = designer.get('description', '')
    designer_category = designer.get('category', 'video')
    
    system_prompt = f"""You are an expert AI image prompt generator specializing in creating VISUAL METAPHORS from script content.

Designer Style: {designer_name}
Description: {designer_desc}
Category: {designer_category}

CRITICAL RULE - VISUAL METAPHOR TRANSFORMATION:
The script text is NOT meant to be literally depicted. You must:
1. Extract the CORE THEME/MESSAGE from the script (economic change, emotional journey, conflict, etc.)
2. Transform that theme into a VISUAL METAPHOR or symbolic imagery
3. Create imagery that REPRESENTS the concept, not illustrates the words literally

EXAMPLE TRANSFORMATIONS:
- Script: "í™˜ìœ¨ì´ ìƒˆë¡œìš´ ë‰´ë…¸ë©€ì´ ë˜ì–´ê°€ê³  ìˆìŠµë‹ˆë‹¤" (Exchange rates becoming the new normal)
  â†’ Visual: Split screen showing vintage calendar with old rates vs futuristic holographic chart with new rates
- Script: "ê·¸ëƒ¥ ì—¬í–‰ ê°ˆ ë•Œ í™˜ì „ ë¹„ìš©ì´ ì¢€ ë” ë“œëŠ” ìˆ˜ì¤€ì˜ ë¬¸ì œê°€ ì•„ë‹™ë‹ˆë‹¤" (This is not just about travel exchange costs)
  â†’ Visual: A passport and dollar bills on a table looking insignificant, dwarfed by a looming shadow
- Script: "ì´ê±´ ëŒ€í•œë¯¼êµ­ ê²½ì œì˜ í˜ˆê´€ì„ íƒ€ê³  íë¥´ëŠ” í”¼ì˜ ì••ë ¥ì´ ìœ„í—˜ ìˆ˜ìœ„ê¹Œì§€ ì¹˜ì†Ÿì•˜ë‹¤" (Economic blood pressure rising)
  â†’ Visual: Medical imagery - pressure gauge in red zone, or blood vessels with pulsing pressure

PROMPT STRUCTURE (Mandatory Format):
[Style], [Context: Abstract theme description], [Visuals: Detailed visual metaphor description]

Where:
- [Style]: Overall visual style (e.g., Modern Cinematic, Documentary Style, Artistic)
- [Context: ...]: The ABSTRACT THEME/CONCEPT being conveyed (NOT the literal script content)
- [Visuals: ...]: Detailed description of the VISUAL METAPHOR - objects, composition, lighting, symbolism

IMPORTANT OUTPUT RULES:
1. FULL_PROMPT must be in ENGLISH ONLY - no Korean characters
2. PROMPT_KO describes the VISUAL IMAGE (not the script) - what objects, composition, mood will be shown
3. The image should SYMBOLIZE the script's meaning, not depict its literal words"""

    user_prompt = f"""Korean Script (extract the THEME, don't depict literally): "{script_text}"
Keywords: {', '.join(keywords) if keywords else 'none'}
Emotion/Mood: {emotion}

TASK: Create a VISUAL METAPHOR that represents the script's core message/theme.
DO NOT simply describe or translate the script text.
Instead, think: "What IMAGE would SYMBOLIZE this concept?"

Return in this EXACT format:
STYLE_TAG: [visual style - e.g., Modern Cinematic, Documentary, Artistic]
CONTEXT_TAG: [Context: abstract theme - e.g., "Context: Economic transformation", "Context: Hidden dangers"]
CORE_DESCRIPTION: detailed VISUAL METAPHOR description (objects, composition, symbolism) in ENGLISH ONLY
VISUAL_DETAILS: [Visuals: specific visual elements - lighting, camera angle, mood, composition details]
PROMPT_KO: ì´ë¯¸ì§€ì˜ ì‹œê°ì  êµ¬ì„± ì„¤ëª… (ì–´ë–¤ ì˜¤ë¸Œì íŠ¸ê°€ ë³´ì´ëŠ”ì§€, êµ¬ë„, ì¡°ëª…, ë¶„ìœ„ê¸° - ëŒ€ë³¸ ë‚´ìš© X)
FULL_PROMPT: [Style], [Context: theme], [Visuals: detailed visual metaphor] - ENGLISH ONLY, no Korean"""

    try:
        import re
        response_text = ""
        
        if provider == "gemini" and runtime_settings["api_keys"]["gemini"]:
            import google.generativeai as genai
            genai.configure(api_key=runtime_settings["api_keys"]["gemini"])
            model = genai.GenerativeModel("gemini-2.0-flash")
            response = model.generate_content(f"{system_prompt}\n\n{user_prompt}")
            response_text = response.text.strip()
            
        elif provider in ["openai", "gpt4o_mini"] and runtime_settings["api_keys"]["openai"]:
            model_name = "gpt-4o-mini" if provider == "gpt4o_mini" else "gpt-4o"
            async with httpx.AsyncClient() as client:
                response = await client.post(
                    "https://api.openai.com/v1/chat/completions",
                    headers={"Authorization": f"Bearer {runtime_settings['api_keys']['openai']}"},
                    json={
                        "model": model_name,
                        "messages": [
                            {"role": "system", "content": system_prompt},
                            {"role": "user", "content": user_prompt}
                        ],
                        "max_tokens": 800
                    },
                    timeout=30
                )
                data = response.json()
                response_text = data["choices"][0]["message"]["content"].strip()
                
        elif provider == "claude" and runtime_settings["api_keys"]["claude"]:
            async with httpx.AsyncClient() as client:
                response = await client.post(
                    "https://api.anthropic.com/v1/messages",
                    headers={
                        "x-api-key": runtime_settings["api_keys"]["claude"],
                        "anthropic-version": "2023-06-01",
                        "content-type": "application/json"
                    },
                    json={
                        "model": "claude-sonnet-4-20250514",
                        "max_tokens": 800,
                        "messages": [{"role": "user", "content": f"{system_prompt}\n\n{user_prompt}"}]
                    },
                    timeout=30
                )
                data = response.json()
                response_text = data["content"][0]["text"].strip()
        else:
            return build_midjourney_prompt(scene, designer)
        
        # ì‘ë‹µ íŒŒì‹±
        style_tag = ""
        context_tag = ""
        core_description = ""
        visual_details = ""
        prompt_ko = ""
        full_prompt = ""
        
        for line in response_text.split("\n"):
            line = line.strip()
            if line.startswith("STYLE_TAG:"):
                style_tag = line.replace("STYLE_TAG:", "").strip()
            elif line.startswith("CONTEXT_TAG:"):
                context_tag = line.replace("CONTEXT_TAG:", "").strip()
            elif line.startswith("CORE_DESCRIPTION:"):
                core_description = line.replace("CORE_DESCRIPTION:", "").strip()
            elif line.startswith("VISUAL_DETAILS:"):
                visual_details = line.replace("VISUAL_DETAILS:", "").strip()
            elif line.startswith("PROMPT_KO:"):
                prompt_ko = line.replace("PROMPT_KO:", "").strip()
            elif line.startswith("FULL_PROMPT:"):
                full_prompt = line.replace("FULL_PROMPT:", "").strip()
        
        # êµ¬ì¡°í™”ëœ í”„ë¡¬í”„íŠ¸ ì¡°í•© (í•œê¸€ì´ ì—†ëŠ” ê²½ìš°)
        if not full_prompt:
            full_prompt = f"{style_tag} {context_tag} {core_description} {visual_details}".strip()
        
        # ì˜ë¬¸ í”„ë¡¬í”„íŠ¸ì—ì„œ í•œê¸€ ì œê±° (ì•ˆì „ì¥ì¹˜)
        if re.search('[ê°€-í£]', full_prompt):
            full_prompt = re.sub('[ê°€-í£]+', '', full_prompt).strip()
            # ì¤‘ë³µ ê³µë°± ì œê±°
            full_prompt = re.sub(' +', ' ', full_prompt)
        
        # ë””ìì´ë„ˆ suffix ì¶”ê°€
        final_prompt = f"{full_prompt} {designer.get('prompt_suffix', '')}".strip()
        
        # í•œê¸€ ì„¤ëª…ì´ ì—†ìœ¼ë©´ ê¸°ë³¸ ì„¤ëª… ìƒì„± (ëŒ€ë³¸ì´ ì•„ë‹Œ ì´ë¯¸ì§€ ì„¤ëª…)
        if not prompt_ko:
            emotion_ko = {
                "neutral": "ì°¨ë¶„í•œ",
                "curious": "í˜¸ê¸°ì‹¬ ê°€ë“í•œ",
                "happy": "ë°ê³  ì¦ê±°ìš´",
                "sad": "ê°ì„±ì ì¸",
                "excited": "ì—­ë™ì ì¸",
                "serious": "ì§„ì§€í•œ",
                "warm": "ë”°ëœ»í•œ",
                "dramatic": "ë“œë¼ë§ˆí‹±í•œ"
            }.get(emotion, "ìì—°ìŠ¤ëŸ¬ìš´")
            prompt_ko = f"{emotion_ko} ë¶„ìœ„ê¸°ì˜ ì´ë¯¸ì§€. ì‹œê°ì  ì¥ë©´ ë¬˜ì‚¬."
        
        return {
            "scene_id": scene.get("scene_id", 0),
            "script_text": script_text,
            "prompt_en": final_prompt,
            "prompt_ko": prompt_ko,
            "structured": {
                "style_tag": style_tag,
                "context_tag": context_tag,
                "core_description": core_description,
                "visual_details": visual_details
            },
            "negative_prompt": designer.get("negative_prompt", ""),
            "keywords": keywords,
            "emotion": emotion,
            "designer_id": designer.get("id", ""),
            "status": "ready"
        }
        
    except Exception as e:
        result = build_midjourney_prompt(scene, designer)
        result["error"] = str(e)
        return result

async def recommend_designer(description: str, scenes: List[Dict] = None, provider: str = "gemini") -> Dict:
    """ëŒ€ë³¸ ë‚´ìš©ì„ ë¶„ì„í•˜ì—¬ ê°€ì¥ ì í•©í•œ ë””ìì´ë„ˆ ì¶”ì²œ"""
    all_designers = get_all_designers()
    
    # ì¹´í…Œê³ ë¦¬ë³„ë¡œ ë””ìì´ë„ˆ ì •ë¦¬
    designer_list = ""
    for group_id, group_info in CATEGORY_GROUPS.items():
        designer_list += f"\n## {group_info['name']} ({group_info['description']}):\n"
        for d_id, d_info in all_designers.items():
            if d_info.get("category", "") in group_info["categories"]:
                best_for = ", ".join(d_info.get("best_for", []))
                designer_list += f"- {d_id}: {d_info['name']} - {d_info['description']} (ì í•©: {best_for})\n"
    
    # ëŒ€ë³¸ ë‚´ìš© ì¶”ì¶œ
    script_content = ""
    if scenes:
        script_texts = [s.get("script_text", "") for s in scenes if s.get("script_text")]
        script_content = "\n".join(script_texts[:5])  # ì²˜ìŒ 5ê°œ ì¥ë©´ë§Œ
    
    system_prompt = f"""You are an expert AI that analyzes video scripts and recommends the best visual style/designer.

Available Designer Styles (organized by category):
{designer_list}

Your task:
1. Analyze the script/description content
2. Identify the tone, genre, target audience, and visual requirements
3. Recommend the most suitable designer style
4. Explain WHY this style fits the content"""

    # ìŠ¤í¬ë¦½íŠ¸ í¬í•¨ ì—¬ë¶€ì— ë”°ë¼ ë‹¤ë¥¸ í”„ë¡¬í”„íŠ¸
    if script_content:
        user_prompt = f"""Analyze this Korean script content and recommend the best designer style:

=== SCRIPT CONTENT ===
{script_content}
======================

User additional notes: "{description}"

Based on the script's tone, content type, and visual requirements, recommend the best designer.

Return in this EXACT format:
RECOMMENDED: [designer_id]
REASON_KO: [í•œê¸€ë¡œ ì¶”ì²œ ì´ìœ  ì„¤ëª… - ì™œ ì´ ìŠ¤íƒ€ì¼ì´ ëŒ€ë³¸ì— ì í•©í•œì§€]
REASON_EN: [English explanation]
ALTERNATIVES: [comma separated alternative designer_ids]
ANALYSIS: [Brief analysis of the script - tone, genre, target audience]"""
    else:
        user_prompt = f"""User description: "{description}"

Recommend the best designer for this description.

Return in this EXACT format:
RECOMMENDED: [designer_id]
REASON_KO: [í•œê¸€ë¡œ ì¶”ì²œ ì´ìœ  ì„¤ëª…]
REASON_EN: [English explanation]
ALTERNATIVES: [comma separated alternative designer_ids]"""

    try:
        response_text = ""
        
        if provider == "gemini" and runtime_settings["api_keys"]["gemini"]:
            import google.generativeai as genai
            genai.configure(api_key=runtime_settings["api_keys"]["gemini"])
            model = genai.GenerativeModel("gemini-2.0-flash")
            response = model.generate_content(f"{system_prompt}\n\n{user_prompt}")
            response_text = response.text.strip()
            
        elif provider in ["openai", "gpt4o_mini"] and runtime_settings["api_keys"]["openai"]:
            model_name = "gpt-4o-mini" if provider == "gpt4o_mini" else "gpt-4o"
            async with httpx.AsyncClient() as client:
                response = await client.post(
                    "https://api.openai.com/v1/chat/completions",
                    headers={"Authorization": f"Bearer {runtime_settings['api_keys']['openai']}"},
                    json={
                        "model": model_name,
                        "messages": [
                            {"role": "system", "content": system_prompt},
                            {"role": "user", "content": user_prompt}
                        ],
                        "max_tokens": 500
                    },
                    timeout=30
                )
                data = response.json()
                response_text = data["choices"][0]["message"]["content"].strip()
        
        # íŒŒì‹±
        recommended = "bright_cheerful"
        reason_ko = ""
        reason_en = ""
        alternatives = []
        analysis = ""
        
        for line in response_text.split("\n"):
            if line.startswith("RECOMMENDED:"):
                recommended = line.replace("RECOMMENDED:", "").strip()
            elif line.startswith("REASON_KO:"):
                reason_ko = line.replace("REASON_KO:", "").strip()
            elif line.startswith("REASON_EN:"):
                reason_en = line.replace("REASON_EN:", "").strip()
            elif line.startswith("REASON:"):
                reason_ko = line.replace("REASON:", "").strip()
            elif line.startswith("ALTERNATIVES:"):
                alts = line.replace("ALTERNATIVES:", "").strip()
                alternatives = [a.strip() for a in alts.split(",")]
            elif line.startswith("ANALYSIS:"):
                analysis = line.replace("ANALYSIS:", "").strip()
        
        # ë””ìì´ë„ˆ ê²€ì¦
        if recommended not in all_designers:
            recommended = "bright_cheerful"
        
        return {
            "success": True,
            "recommended": recommended,
            "recommended_designer": all_designers.get(recommended, all_designers.get("bright_cheerful")),
            "reason": reason_ko or reason_en,
            "reason_ko": reason_ko,
            "reason_en": reason_en,
            "analysis": analysis,
            "alternatives": [a for a in alternatives[:3] if a in all_designers],
            "script_analyzed": bool(script_content)
        }
        
    except Exception as e:
        return {
            "success": False,
            "error": str(e),
            "recommended": "bright_cheerful",
            "recommended_designer": PRESET_DESIGNERS["bright_cheerful"]
        }

# ============================================
# ì¸ë„¤ì¼ í”„ë¡¬í”„íŠ¸ ìƒì„± í•¨ìˆ˜
# ============================================
async def generate_thumbnail_prompts(full_script: str, title: str = "", provider: str = "gemini") -> Dict:
    """ì „ì²´ ëŒ€ë³¸ì„ ë¶„ì„í•˜ì—¬ ì¸ë„¤ì¼ìš© í”„ë¡¬í”„íŠ¸ 3ê°œ ìƒì„±

    ì¸ë„¤ì¼ íŠ¹ì§•:
    - ì˜ìƒì˜ í•µì‹¬ ë©”ì‹œì§€ë¥¼ í•œ ì¥ì˜ ì´ë¯¸ì§€ë¡œ í‘œí˜„
    - í•œê¸€ í…ìŠ¤íŠ¸ ë¬¸êµ¬ í¬í•¨ (ì œëª©, í‚¤ì›Œë“œ ë“±)
    - ì‹œì„ ì„ ë„ëŠ” ê°•ë ¬í•œ êµ¬ë„ì™€ ìƒ‰ìƒ
    - ì¥ë©´ í”„ë¡¬í”„íŠ¸ì²˜ëŸ¼ ì„¸ë¶€ì ì¸ ì‹œê°ì  ì€ìœ  í˜•ì‹ ì‚¬ìš©
    """

    system_prompt = """You are an expert YouTube thumbnail designer specializing in creating VISUAL METAPHORS from script content.

CRITICAL RULE - VISUAL METAPHOR TRANSFORMATION:
The script text is NOT meant to be literally depicted. You must:
1. Extract the CORE THEME/MESSAGE from the entire script
2. Transform that theme into a POWERFUL VISUAL METAPHOR
3. Create imagery that REPRESENTS the concept symbolically
4. Design for maximum click appeal and curiosity

THUMBNAIL DESIGN PRINCIPLES:
1. ONE powerful visual metaphor that captures the video's essence
2. Bold, contrasting colors for visual impact (specify exact colors)
3. Clear focal point with dramatic composition
4. Space for Korean text overlay (title, keywords)
5. Emotional appeal - curiosity, shock, excitement, or urgency
6. Cinematic quality with professional lighting

PROMPT STRUCTURE (Mandatory Format for FULL_PROMPT):
[Modern Cinematic], [Context: Abstract theme description], [Visuals: Detailed visual metaphor with specific objects, lighting, composition, camera angle, mood]

KOREAN DESCRIPTION (PROMPT_KO) GUIDELINES:
- Must be in Korean describing the VISUAL IMAGE (not the script content)
- Describe what objects, composition, lighting, mood will be shown
- Example: "ê¸ˆì´ ê°„ ì§€êµ¬ë³¸ ìœ„ì— ë–¨ì–´ì§€ëŠ” ë‹¬ëŸ¬ ì§€íë“¤, ë¶‰ì€ ê²½ê³ ë“± ì¡°ëª…, ê¸´ë°•í•œ ë¶„ìœ„ê¸°"

OUTPUT FORMAT for each thumbnail:
THUMBNAIL_1:
KOREAN_TEXT: [í•œê¸€ í…ìŠ¤íŠ¸ ì˜¤ë²„ë ˆì´ - 2-4ë‹¨ì–´ ì„íŒ©íŠ¸ ìˆëŠ” ë¬¸êµ¬ (ì˜ˆ: "ì¶©ê²© ì§„ì‹¤", "ì§€ê¸ˆ ë‹¹ì¥")]
PROMPT_KO: [ì‹œê°ì  ì´ë¯¸ì§€ í•œê¸€ ì„¤ëª… - ì–´ë–¤ ì˜¤ë¸Œì íŠ¸, êµ¬ë„, ì¡°ëª…, ë¶„ìœ„ê¸°ê°€ ë³´ì´ëŠ”ì§€ êµ¬ì²´ì ìœ¼ë¡œ]
FULL_PROMPT: [Modern Cinematic], [Context: theme], [Visuals: detailed description with lighting, camera angle, colors, objects, mood] - ENGLISH ONLY

Generate 3 distinctly different thumbnail concepts with varied visual metaphors."""

    user_prompt = f"""Analyze this Korean script and create 3 VISUALLY STUNNING thumbnail concepts:

TITLE: {title or '(ì œëª© ì—†ìŒ)'}

FULL SCRIPT:
{full_script[:3000]}

TASK: Create 3 thumbnail prompts that:
1. Each captures a DIFFERENT aspect or angle of the content using VISUAL METAPHORS
2. Each has unique Korean text overlay (KOREAN_TEXT) for impact
3. Each has Korean visual description (PROMPT_KO) describing the image composition
4. Would make viewers IMMEDIATELY want to click
5. Uses the structured format: [Style], [Context: theme], [Visuals: detailed description]

Return in this EXACT format for each:
THUMBNAIL_1:
KOREAN_TEXT: [ì„íŒ©íŠ¸ ìˆëŠ” í•œê¸€ ë¬¸êµ¬ 2-4ë‹¨ì–´]
PROMPT_KO: [ì´ë¯¸ì§€ì˜ ì‹œê°ì  êµ¬ì„±ì„ í•œê¸€ë¡œ ì„¤ëª… - ì˜¤ë¸Œì íŠ¸, êµ¬ë„, ì¡°ëª…, ë¶„ìœ„ê¸°]
FULL_PROMPT: [Modern Cinematic], [Context: abstract theme], [Visuals: detailed visual metaphor with lighting, camera angle, specific objects, colors, mood]

THUMBNAIL_2:
KOREAN_TEXT: ...
PROMPT_KO: ...
FULL_PROMPT: ...

THUMBNAIL_3:
KOREAN_TEXT: ...
PROMPT_KO: ...
FULL_PROMPT: ..."""

    try:
        response_text = ""

        if provider == "gemini" and runtime_settings["api_keys"]["gemini"]:
            import google.generativeai as genai
            genai.configure(api_key=runtime_settings["api_keys"]["gemini"])
            model = genai.GenerativeModel("gemini-2.0-flash")
            response = model.generate_content(f"{system_prompt}\n\n{user_prompt}")
            response_text = response.text.strip()

        elif provider in ["openai", "gpt4o_mini"] and runtime_settings["api_keys"]["openai"]:
            model_name = "gpt-4o-mini" if provider == "gpt4o_mini" else "gpt-4o"
            async with httpx.AsyncClient() as client:
                response = await client.post(
                    "https://api.openai.com/v1/chat/completions",
                    headers={"Authorization": f"Bearer {runtime_settings['api_keys']['openai']}"},
                    json={
                        "model": model_name,
                        "messages": [
                            {"role": "system", "content": system_prompt},
                            {"role": "user", "content": user_prompt}
                        ],
                        "max_tokens": 2000
                    },
                    timeout=60
                )
                data = response.json()
                response_text = data["choices"][0]["message"]["content"].strip()

        elif provider == "claude" and runtime_settings["api_keys"]["claude"]:
            async with httpx.AsyncClient() as client:
                response = await client.post(
                    "https://api.anthropic.com/v1/messages",
                    headers={
                        "x-api-key": runtime_settings["api_keys"]["claude"],
                        "anthropic-version": "2023-06-01",
                        "content-type": "application/json"
                    },
                    json={
                        "model": "claude-sonnet-4-20250514",
                        "max_tokens": 2000,
                        "messages": [{"role": "user", "content": f"{system_prompt}\n\n{user_prompt}"}]
                    },
                    timeout=60
                )
                data = response.json()
                response_text = data["content"][0]["text"].strip()
        else:
            return {"success": False, "error": "AI í”„ë¡œë°”ì´ë”ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."}

        # ì‘ë‹µ íŒŒì‹±
        thumbnails = []
        current_thumbnail = {}

        for line in response_text.split("\n"):
            line = line.strip()

            if line.startswith("THUMBNAIL_"):
                if current_thumbnail:
                    thumbnails.append(current_thumbnail)
                current_thumbnail = {"id": len(thumbnails) + 1}
            elif line.startswith("KOREAN_TEXT:"):
                current_thumbnail["korean_text"] = line.replace("KOREAN_TEXT:", "").strip()
            elif line.startswith("PROMPT_KO:"):
                current_thumbnail["prompt_ko"] = line.replace("PROMPT_KO:", "").strip()
            elif line.startswith("VISUAL_CONCEPT:"):
                # ë ˆê±°ì‹œ ì§€ì› - prompt_koê°€ ì—†ìœ¼ë©´ visual_concept ì‚¬ìš©
                if "prompt_ko" not in current_thumbnail:
                    current_thumbnail["prompt_ko"] = line.replace("VISUAL_CONCEPT:", "").strip()
            elif line.startswith("FULL_PROMPT:"):
                current_thumbnail["prompt_en"] = line.replace("FULL_PROMPT:", "").strip()

        # ë§ˆì§€ë§‰ ì¸ë„¤ì¼ ì¶”ê°€
        if current_thumbnail:
            thumbnails.append(current_thumbnail)

        # ìµœì†Œ 3ê°œ ë³´ì¥ ë° prompt_ko ê¸°ë³¸ê°’ ì„¤ì •
        while len(thumbnails) < 3:
            thumbnails.append({
                "id": len(thumbnails) + 1,
                "korean_text": "í´ë¦­ í•„ìˆ˜!",
                "prompt_ko": "ê°•ë ¬í•œ ìƒ‰ìƒì˜ ì‹œì„ ì„ ë„ëŠ” ì¸ë„¤ì¼ ì´ë¯¸ì§€, ì¤‘ì•™ í¬ì»¤ìŠ¤ êµ¬ë„",
                "prompt_en": "[Modern Cinematic], [Context: Attention-grabbing visual], [Visuals: Bold contrasting colors, dramatic lighting, centered focal point, professional YouTube thumbnail composition, 16:9 aspect ratio]"
            })

        # prompt_koê°€ ì—†ëŠ” ì¸ë„¤ì¼ì— ê¸°ë³¸ê°’ ì„¤ì •
        for thumb in thumbnails:
            if "prompt_ko" not in thumb or not thumb["prompt_ko"]:
                thumb["prompt_ko"] = thumb.get("korean_text", "ì¸ë„¤ì¼ ì´ë¯¸ì§€")

        return {
            "success": True,
            "thumbnails": thumbnails[:3],
            "title": title,
            "script_preview": full_script[:200] + "..." if len(full_script) > 200 else full_script
        }

    except Exception as e:
        return {
            "success": False,
            "error": str(e),
            "thumbnails": []
        }

# ============================================
# ì´ë¯¸ì§€ ìƒì„± í•¨ìˆ˜
# ============================================
async def generate_image_dalle3(prompt: str, negative_prompt: str, size: str) -> Dict:
    """DALL-E 3ë¡œ ì´ë¯¸ì§€ ìƒì„±"""
    api_key = runtime_settings["api_keys"]["openai"]
    if not api_key:
        return {"success": False, "error": "OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."}
    
    full_prompt = f"{prompt}. Avoid: {negative_prompt}" if negative_prompt else prompt
    
    try:
        async with httpx.AsyncClient() as client:
            response = await client.post(
                "https://api.openai.com/v1/images/generations",
                headers={"Authorization": f"Bearer {api_key}"},
                json={
                    "model": "dall-e-3",
                    "prompt": full_prompt,
                    "size": size,
                    "quality": "hd",
                    "n": 1
                },
                timeout=60
            )
            data = response.json()
            
            if "data" in data and len(data["data"]) > 0:
                return {
                    "success": True,
                    "image_url": data["data"][0]["url"],
                    "provider": "dalle3",
                    "revised_prompt": data["data"][0].get("revised_prompt", "")
                }
            return {"success": False, "error": data.get("error", {}).get("message", "Unknown error")}
                
    except Exception as e:
        return {"success": False, "error": str(e)}

async def generate_image_replicate(prompt: str, negative_prompt: str, aspect_ratio: str, model: str = "flux-schnell") -> Dict:
    """Replicateë¡œ ì´ë¯¸ì§€ ìƒì„± (ë‹¤ì–‘í•œ ëª¨ë¸ ì§€ì›)

    ì§€ì› ëª¨ë¸:
    - flux-schnell: black-forest-labs/flux-schnell (ê¸°ë³¸, ë¹ ë¥¸ ìƒì„±)
    - seedream-4: bytedance/seedream-4 (ByteDanceì˜ ê³ í’ˆì§ˆ ëª¨ë¸)
    - nano-banana: google/nano-banana (Googleì˜ ê²½ëŸ‰ ëª¨ë¸)
    - nano-banana-pro: google/nano-banana-pro (Googleì˜ ê³ í’ˆì§ˆ ëª¨ë¸)
    """
    api_key = runtime_settings["api_keys"]["replicate"]
    if not api_key:
        return {"success": False, "error": "Replicate API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."}

    try:
        import replicate
        os.environ["REPLICATE_API_TOKEN"] = api_key

        # ëª¨ë¸ë³„ ì„¤ì •
        model_configs = {
            "flux-schnell": {
                "model_id": "black-forest-labs/flux-schnell",
                "input": {
                    "prompt": prompt,
                    "aspect_ratio": aspect_ratio,
                    "output_format": "webp",
                    "output_quality": 80
                }
            },
            "seedream-4": {
                "model_id": "bytedance/seedream-4",
                "input": {
                    "prompt": prompt,
                    "negative_prompt": negative_prompt or "",
                    "aspect_ratio": aspect_ratio,
                    "num_outputs": 1
                }
            },
            "nano-banana": {
                "model_id": "google/nano-banana",
                "input": {
                    "prompt": prompt,
                    "negative_prompt": negative_prompt or "",
                    "aspect_ratio": aspect_ratio,
                    "num_outputs": 1
                }
            },
            "nano-banana-pro": {
                "model_id": "google/nano-banana-pro",
                "input": {
                    "prompt": prompt,
                    "negative_prompt": negative_prompt or "",
                    "aspect_ratio": aspect_ratio,
                    "num_outputs": 1
                }
            }
        }

        # ëª¨ë¸ ì„¤ì • ê°€ì ¸ì˜¤ê¸° (ê¸°ë³¸ê°’: flux-schnell)
        config = model_configs.get(model, model_configs["flux-schnell"])

        output = replicate.run(
            config["model_id"],
            input=config["input"]
        )

        if output:
            image_url = str(output[0]) if isinstance(output, list) else str(output)
            return {"success": True, "image_url": image_url, "provider": "replicate", "model": model}
        return {"success": False, "error": "ì´ë¯¸ì§€ ìƒì„± ì‹¤íŒ¨"}

    except Exception as e:
        return {"success": False, "error": str(e)}

async def generate_image_vertex(prompt: str, negative_prompt: str, size: str, model: str = "auto") -> Dict:
    """Google Vertex AI / Nano Bananaë¡œ ì´ë¯¸ì§€ ìƒì„±

    ì§€ì› ëª¨ë¸:
    - auto: ìë™ ì„ íƒ (imagen-4.0-fast-generate-001 ìš°ì„ )
    - nano-banana: imagen-3.0-generate-002 (Nano Banana)
    - imagen-4-fast: imagen-4.0-fast-generate-001
    - imagen-4-ultra: imagen-4.0-ultra-generate-001
    - gemini-image: gemini-2.0-flash-exp-image-generation

    ìƒˆë¡œìš´ google-genai SDK ì‚¬ìš©
    """
    api_key = runtime_settings["api_keys"]["vertex"] or runtime_settings["api_keys"]["gemini"]
    if not api_key:
        return {"success": False, "error": "Vertex AI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."}

    try:
        from google import genai
        from google.genai import types
        import base64
        import io

        # í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
        client = genai.Client(api_key=api_key)

        # ë¹„ìœ¨ ì„¤ì •
        aspect_ratio = "16:9" if "1792" in size else "1:1" if "1024x1024" in size else "9:16"

        # ëª¨ë¸ ë§¤í•‘ (ì‹¤ì œ Google AIì—ì„œ ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ëª…)
        # Nano BananaëŠ” Imagen 4.0 Fastì˜ ì½”ë“œëª…ìœ¼ë¡œ ì¶”ì •
        model_map = {
            "nano-banana": "imagen-4.0-fast-generate-001",     # Nano Banana = Imagen 4.0 Fast
            "nano-banana-pro": "imagen-4.0-ultra-generate-001", # Nano Banana Pro = Imagen 4.0 Ultra
            "imagen-4-fast": "imagen-4.0-fast-generate-001",
            "imagen-4-ultra": "imagen-4.0-ultra-generate-001",
            "gemini-image": "gemini-2.0-flash-exp-image-generation"
        }

        # ëª¨ë¸ ì„ íƒ
        if model != "auto" and model in model_map:
            # íŠ¹ì • ëª¨ë¸ ì§€ì •ëœ ê²½ìš° í•´ë‹¹ ëª¨ë¸ë§Œ ì‹œë„
            imagen_models = [model_map[model]]
        else:
            # auto ëª¨ë“œ: ìˆœì°¨ì ìœ¼ë¡œ ì‹œë„
            imagen_models = [
                "imagen-4.0-fast-generate-001",      # Imagen 4.0 Fast (ë¹ ë¥¸ ìƒì„±)
                "imagen-3.0-generate-001",           # Imagen 3.0 (Nano Banana)
                "imagen-4.0-ultra-generate-001",     # Imagen 4.0 Ultra (ê³ í’ˆì§ˆ)
                "gemini-2.0-flash-exp-image-generation",  # Gemini ì´ë¯¸ì§€ ìƒì„±
            ]
        
        last_error = None
        
        for model_name in imagen_models:
            try:
                result = client.models.generate_images(
                    model=model_name,
                    prompt=prompt,
                    config=types.GenerateImagesConfig(
                        number_of_images=1,
                        aspect_ratio=aspect_ratio,
                    )
                )
                
                if result.generated_images and len(result.generated_images) > 0:
                    # ì²« ë²ˆì§¸ ì´ë¯¸ì§€ ê°€ì ¸ì˜¤ê¸°
                    image = result.generated_images[0]
                    
                    # ì´ë¯¸ì§€ ë°ì´í„°ë¥¼ base64ë¡œ ì¸ì½”ë”©
                    if hasattr(image, 'image') and hasattr(image.image, 'image_bytes'):
                        img_bytes = image.image.image_bytes
                    elif hasattr(image, 'image_bytes'):
                        img_bytes = image.image_bytes
                    else:
                        # PIL ì´ë¯¸ì§€ë¡œ ë³€í™˜ ì‹œë„
                        from PIL import Image
                        if hasattr(image, 'image'):
                            pil_image = image.image._pil_image if hasattr(image.image, '_pil_image') else image.image
                        else:
                            pil_image = image._pil_image if hasattr(image, '_pil_image') else image
                        
                        buffer = io.BytesIO()
                        pil_image.save(buffer, format="PNG")
                        img_bytes = buffer.getvalue()
                    
                    img_str = base64.b64encode(img_bytes).decode()
                    
                    return {
                        "success": True,
                        "image_url": f"data:image/png;base64,{img_str}",
                        "provider": "vertex",
                        "model": model_name
                    }
                    
            except Exception as model_error:
                last_error = str(model_error)
                # ëª¨ë¸ì´ ì§€ì›ë˜ì§€ ì•Šìœ¼ë©´ ë‹¤ìŒ ëª¨ë¸ ì‹œë„
                if "not found" in last_error.lower() or "not supported" in last_error.lower():
                    continue
                # ë‹¤ë¥¸ ì—ëŸ¬ë„ ë‹¤ìŒ ëª¨ë¸ë¡œ ì‹œë„
                continue
        
        # ëª¨ë“  ëª¨ë¸ ì‹¤íŒ¨ ì‹œ
        return {"success": False, "error": f"ì´ë¯¸ì§€ ìƒì„± ì‹¤íŒ¨: {last_error}"}
        
    except ImportError:
        return {"success": False, "error": "google-genai íŒ¨í‚¤ì§€ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. 'pip install google-genai' ëª…ë ¹ìœ¼ë¡œ ì„¤ì¹˜í•˜ì„¸ìš”."}
    except Exception as e:
        error_msg = str(e)
        if "permission" in error_msg.lower() or "403" in error_msg:
            return {"success": False, "error": "API ì ‘ê·¼ ê¶Œí•œì´ ì—†ìŠµë‹ˆë‹¤. API í‚¤ë¥¼ í™•ì¸í•˜ì„¸ìš”."}
        if "quota" in error_msg.lower() or "429" in error_msg:
            return {"success": False, "error": "API í• ë‹¹ëŸ‰ ì´ˆê³¼. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•˜ì„¸ìš”."}
        if "billing" in error_msg.lower():
            return {"success": False, "error": "ê²°ì œ ì„¤ì •ì´ í•„ìš”í•©ë‹ˆë‹¤. Google Cloud ê²°ì œë¥¼ í™œì„±í™”í•˜ì„¸ìš”."}
        return {"success": False, "error": error_msg}

async def generate_image(prompt: str, negative_prompt: str = "", provider: str = "dalle3", size: str = "1792x1024", model: str = None) -> Dict:
    """í†µí•© ì´ë¯¸ì§€ ìƒì„± í•¨ìˆ˜

    ì§€ì› providerì™€ ëª¨ë¸:
    - dalle3: OpenAI DALL-E 3
    - replicate: Replicate (flux-schnell, seedream-4, nano-banana, nano-banana-pro)
    - vertex: Vertex AI (nano-banana, imagen-4-fast, imagen-4-ultra, gemini-image)
    - vertex-nano-banana: Vertex AI Nano Banana ì§ì ‘ í˜¸ì¶œ
    - replicate-seedream: Replicate SeeDream-4 ì§ì ‘ í˜¸ì¶œ
    - replicate-nano-banana: Replicate Nano Banana ì§ì ‘ í˜¸ì¶œ
    - replicate-nano-banana-pro: Replicate Nano Banana Pro ì§ì ‘ í˜¸ì¶œ
    """
    aspect_map = {"1792x1024": "16:9", "1024x1792": "9:16", "1024x1024": "1:1"}
    aspect_ratio = aspect_map.get(size, "16:9")

    if provider == "dalle3":
        return await generate_image_dalle3(prompt, negative_prompt, size)
    elif provider == "replicate":
        return await generate_image_replicate(prompt, negative_prompt, aspect_ratio, model or "flux-schnell")
    elif provider == "replicate-seedream":
        return await generate_image_replicate(prompt, negative_prompt, aspect_ratio, "seedream-4")
    elif provider == "replicate-nano-banana":
        return await generate_image_replicate(prompt, negative_prompt, aspect_ratio, "nano-banana")
    elif provider == "replicate-nano-banana-pro":
        return await generate_image_replicate(prompt, negative_prompt, aspect_ratio, "nano-banana-pro")
    elif provider == "vertex":
        return await generate_image_vertex(prompt, negative_prompt, size, model or "auto")
    elif provider == "vertex-nano-banana":
        return await generate_image_vertex(prompt, negative_prompt, size, "nano-banana")
    elif provider == "vertex-nano-banana-pro":
        return await generate_image_vertex(prompt, negative_prompt, size, "nano-banana-pro")
    else:
        return {"success": False, "error": f"Unknown provider: {provider}"}

# ============================================
# API Endpoints - ì„¤ì •
# ============================================
@app.get("/health")
async def health_check():
    return {"status": "healthy", "module": "image-generator", "version": "2.6.0"}

@app.post("/api/settings/test-api-key")
async def test_api_key(data: ApiKeyTest):
    provider = data.provider
    api_key = data.api_key
    
    try:
        if provider == "openai":
            async with httpx.AsyncClient() as client:
                response = await client.get(
                    "https://api.openai.com/v1/models",
                    headers={"Authorization": f"Bearer {api_key}"},
                    timeout=10
                )
                if response.status_code == 200:
                    return {"success": True, "message": "OpenAI API ì—°ê²° ì„±ê³µ"}
                return {"success": False, "error": "ì¸ì¦ ì‹¤íŒ¨"}
                
        elif provider == "replicate":
            async with httpx.AsyncClient() as client:
                response = await client.get(
                    "https://api.replicate.com/v1/account",
                    headers={"Authorization": f"Token {api_key}"},
                    timeout=10
                )
                if response.status_code == 200:
                    return {"success": True, "message": "Replicate API ì—°ê²° ì„±ê³µ"}
                return {"success": False, "error": "ì¸ì¦ ì‹¤íŒ¨"}
                
        elif provider == "gemini":
            import google.generativeai as genai
            genai.configure(api_key=api_key)
            model = genai.GenerativeModel("gemini-2.0-flash")
            response = model.generate_content("Say 'OK'")
            if response.text:
                return {"success": True, "message": "Gemini API ì—°ê²° ì„±ê³µ"}
            return {"success": False, "error": "ì‘ë‹µ ì—†ìŒ"}
            
        elif provider == "claude":
            async with httpx.AsyncClient() as client:
                response = await client.post(
                    "https://api.anthropic.com/v1/messages",
                    headers={
                        "x-api-key": api_key,
                        "anthropic-version": "2023-06-01",
                        "content-type": "application/json"
                    },
                    json={
                        "model": "claude-sonnet-4-20250514",
                        "max_tokens": 10,
                        "messages": [{"role": "user", "content": "Say OK"}]
                    },
                    timeout=10
                )
                if response.status_code == 200:
                    return {"success": True, "message": "Claude API ì—°ê²° ì„±ê³µ"}
                return {"success": False, "error": "ì¸ì¦ ì‹¤íŒ¨"}
                
        elif provider == "vertex":
            import google.generativeai as genai
            genai.configure(api_key=api_key)
            # Vertex AI í‚¤ ê²€ì¦
            model = genai.GenerativeModel("gemini-2.0-flash")
            response = model.generate_content("Say 'OK'")
            if response.text:
                return {"success": True, "message": "Vertex AI ì—°ê²° ì„±ê³µ (Gemini ê²€ì¦)"}
            return {"success": False, "error": "ì‘ë‹µ ì—†ìŒ"}
        else:
            return {"success": False, "error": f"Unknown provider: {provider}"}
            
    except Exception as e:
        return {"success": False, "error": str(e)}

@app.post("/api/settings/save")
async def save_api_keys(data: Dict):
    for provider, key in data.items():
        if provider in runtime_settings["api_keys"]:
            runtime_settings["api_keys"][provider] = key
    
    secrets_path = BASE_DIR / "api_secrets.json"
    secrets = {}
    if secrets_path.exists():
        with open(secrets_path, 'r', encoding='utf-8') as f:
            secrets = json.load(f)
    
    key_map = {
        "openai": "openai_api_key",
        "replicate": "replicate_api_token",
        "gemini": "gemini_api_key",
        "claude": "claude_api_key",
        "vertex": "vertex_api_key"
    }
    
    for provider, key in data.items():
        if provider in key_map and key:
            secrets[key_map[provider]] = key
    
    with open(secrets_path, 'w', encoding='utf-8') as f:
        json.dump(secrets, f, indent=2, ensure_ascii=False)
    
    return {"success": True, "message": "API í‚¤ ì €ì¥ ì™„ë£Œ"}

@app.get("/api/settings")
async def get_settings():
    masked = {}
    for provider, key in runtime_settings["api_keys"].items():
        if key:
            masked[provider] = {"configured": True, "masked": key[:8] + "..." + key[-4:] if len(key) > 12 else "***"}
        else:
            masked[provider] = {"configured": False, "masked": None}
    return {"api_keys": masked, "default_provider": runtime_settings["default_provider"]}

# API Endpoints - ë””ìì´ë„ˆ
# ============================================
@app.get("/api/designers")
async def list_designers():
    all_designers = get_all_designers()
    favorites = get_favorites()
    
    # ì¹´í…Œê³ ë¦¬ë³„ ë¶„ë¥˜
    categorized = {}
    for group_id, group_info in CATEGORY_GROUPS.items():
        categorized[group_id] = {
            "name": group_info["name"],
            "description": group_info["description"],
            "designers": {}
        }
    
    # ê° ë””ìì´ë„ˆë¥¼ ì¹´í…Œê³ ë¦¬ ê·¸ë£¹ì— ë°°ì¹˜
    presets = {}
    custom = {}
    for k, v in all_designers.items():
        # ì¦ê²¨ì°¾ê¸° ì—¬ë¶€ ì¶”ê°€
        v["is_favorite"] = k in favorites
        
        if v.get("is_preset", False):
            presets[k] = v
        else:
            custom[k] = v
        
        # ì¹´í…Œê³ ë¦¬ ê·¸ë£¹ì— í• ë‹¹
        designer_category = v.get("category", "video")
        assigned = False
        for group_id, group_info in CATEGORY_GROUPS.items():
            if designer_category in group_info["categories"]:
                categorized[group_id]["designers"][k] = v
                assigned = True
                break
        
        # í• ë‹¹ ì•ˆëœ ê²½ìš° specialì— ì¶”ê°€
        if not assigned:
            categorized["special"]["designers"][k] = v
    
    return {
        "presets": presets, 
        "custom": custom, 
        "categorized": categorized,
        "category_groups": CATEGORY_GROUPS,
        "favorites": favorites,
        "total": len(all_designers)
    }

@app.get("/api/designers/favorites")
async def get_favorite_designers():
    """ì¦ê²¨ì°¾ê¸° ë””ìì´ë„ˆ ëª©ë¡"""
    favorites = get_favorites()
    all_designers = get_all_designers()
    favorite_designers = {k: v for k, v in all_designers.items() if k in favorites}
    return {"favorites": favorites, "designers": favorite_designers}

@app.post("/api/designers/{designer_id}/favorite")
async def toggle_favorite(designer_id: str):
    """ì¦ê²¨ì°¾ê¸° í† ê¸€"""
    favorites = get_favorites()
    if designer_id in favorites:
        remove_favorite(designer_id)
        return {"success": True, "is_favorite": False, "message": "ì¦ê²¨ì°¾ê¸°ì—ì„œ ì œê±°ë¨"}
    else:
        add_favorite(designer_id)
        return {"success": True, "is_favorite": True, "message": "ì¦ê²¨ì°¾ê¸°ì— ì¶”ê°€ë¨"}

@app.get("/api/designers/{designer_id}")
async def get_designer_detail(designer_id: str):
    designer = get_designer(designer_id)
    if not designer:
        raise HTTPException(status_code=404, detail="ë””ìì´ë„ˆë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    return designer

@app.post("/api/designers")
async def create_designer(data: CustomDesigner):
    custom = get_custom_designers()
    designer_id = f"custom_{datetime.now().strftime('%Y%m%d%H%M%S')}"
    
    new_designer = {
        "id": designer_id,
        "name": data.name,
        "description": data.description,
        "category": data.category,
        "is_preset": False,
        "prompt_prefix": data.prompt_prefix,
        "prompt_suffix": data.prompt_suffix,
        "negative_prompt": data.negative_prompt,
        "best_for": data.best_for,
        "created_at": datetime.now().isoformat()
    }
    
    custom[designer_id] = new_designer
    save_custom_designers(custom)
    
    return {"success": True, "designer": new_designer}

@app.put("/api/designers/{designer_id}")
async def update_designer(designer_id: str, data: CustomDesigner):
    if designer_id in PRESET_DESIGNERS:
        raise HTTPException(status_code=400, detail="í”„ë¦¬ì…‹ ë””ìì´ë„ˆëŠ” ìˆ˜ì •í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    
    custom = get_custom_designers()
    if designer_id not in custom:
        raise HTTPException(status_code=404, detail="ë””ìì´ë„ˆë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    
    custom[designer_id].update({
        "name": data.name,
        "description": data.description,
        "category": data.category,
        "prompt_prefix": data.prompt_prefix,
        "prompt_suffix": data.prompt_suffix,
        "negative_prompt": data.negative_prompt,
        "best_for": data.best_for,
        "updated_at": datetime.now().isoformat()
    })
    
    save_custom_designers(custom)
    return {"success": True, "designer": custom[designer_id]}

@app.delete("/api/designers/{designer_id}")
async def delete_designer(designer_id: str):
    if designer_id in PRESET_DESIGNERS:
        raise HTTPException(status_code=400, detail="í”„ë¦¬ì…‹ ë””ìì´ë„ˆëŠ” ì‚­ì œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    
    custom = get_custom_designers()
    if designer_id not in custom:
        raise HTTPException(status_code=404, detail="ë””ìì´ë„ˆë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    
    del custom[designer_id]
    save_custom_designers(custom)
    return {"success": True, "message": "ì‚­ì œ ì™„ë£Œ"}

@app.post("/api/designers/recommend")
async def api_recommend_designer(data: RecommendDesignerRequest):
    """ëŒ€ë³¸ì„ ë¶„ì„í•˜ì—¬ ë””ìì´ë„ˆ ì¶”ì²œ"""
    result = await recommend_designer(data.description, data.scenes, data.ai_provider)
    return result

# ============================================
# API Endpoints - í”„ë¡¬í”„íŠ¸
# ============================================
@app.post("/api/prompts/generate")
async def generate_prompts(data: PromptGenerateRequest):
    designer = get_designer(data.designer_id) or PRESET_DESIGNERS["bright_cheerful"]
    
    results = []
    for scene in data.scenes:
        prompt_data = build_midjourney_prompt(scene, designer)
        results.append(prompt_data)
    
    return {"success": True, "prompts": results, "designer_used": designer["name"]}

@app.post("/api/prompts/generate-ai")
async def generate_prompts_ai(data: Dict):
    scenes = data.get("scenes", [])
    designer_id = data.get("designer_id", "bright_cheerful")
    ai_provider = data.get("ai_provider", "gemini")
    
    designer = get_designer(designer_id) or PRESET_DESIGNERS["bright_cheerful"]
    
    results = []
    for scene in scenes:
        prompt_data = await generate_prompt_with_ai(scene, designer, ai_provider)
        results.append(prompt_data)
    
    return {"success": True, "prompts": results, "designer_used": designer["name"], "ai_provider": ai_provider}

@app.post("/api/prompts/sync-ko-to-en")
async def sync_korean_to_english(data: KoToEnRequest):
    """í•œê¸€ ëŒ€ë³¸ â†’ ì‹œê°ì  ì€ìœ  í”„ë¡¬í”„íŠ¸ ìƒì„± (ì˜ë¬¸ + í•œê¸€ ì´ë¯¸ì§€ ì„¤ëª…)"""
    designer = get_designer(data.designer_id) or PRESET_DESIGNERS["bright_cheerful"]

    # korean_text ë˜ëŠ” korean_description ì¤‘ í•˜ë‚˜ ì‚¬ìš©
    korean_input = data.korean_text or data.korean_description
    if not korean_input:
        return {"success": False, "error": "í•œê¸€ ì„¤ëª…ì„ ì…ë ¥í•˜ì„¸ìš”"}

    # generate_prompt_with_aië¥¼ ì‚¬ìš©í•˜ì—¬ ì‹œê°ì  ì€ìœ ë¡œ ë³€í™˜
    scene = {
        "scene_id": 0,
        "script_text": korean_input,
        "keywords": [],
        "emotion": "neutral"
    }

    result = await generate_prompt_with_ai(scene, designer, data.ai_provider)

    return {
        "success": True,
        "prompt_en": result.get("prompt_en", ""),
        "prompt_ko": result.get("prompt_ko", ""),  # ì‹œê°ì  ì€ìœ ë¡œ ë³€í™˜ëœ í•œê¸€ ì„¤ëª…
        "negative_prompt": result.get("negative_prompt", designer.get("negative_prompt", "")),
        "structured": result.get("structured", {})
    }

class ThumbnailRequest(BaseModel):
    full_script: str
    title: Optional[str] = ""
    ai_provider: Optional[str] = "gemini"

@app.post("/api/thumbnails/generate")
async def generate_thumbnails(data: ThumbnailRequest):
    """ì „ì²´ ëŒ€ë³¸ì„ ë¶„ì„í•˜ì—¬ ì¸ë„¤ì¼ í”„ë¡¬í”„íŠ¸ 3ê°œ ìƒì„±"""
    result = await generate_thumbnail_prompts(
        full_script=data.full_script,
        title=data.title,
        provider=data.ai_provider
    )
    return result

class ThumbnailImageRequest(BaseModel):
    prompt_en: str
    korean_text: Optional[str] = ""
    provider: Optional[str] = "vertex"
    size: Optional[str] = "1792x1024"
    negative_prompt: Optional[str] = ""

@app.post("/api/thumbnails/generate-image")
async def generate_thumbnail_image(data: ThumbnailImageRequest):
    """ì¸ë„¤ì¼ ì´ë¯¸ì§€ ìƒì„±"""
    # í•œê¸€ í…ìŠ¤íŠ¸ê°€ ìˆìœ¼ë©´ í”„ë¡¬í”„íŠ¸ì— ì¶”ê°€
    prompt = data.prompt_en
    if data.korean_text:
        prompt = f"{prompt}. Include bold Korean text overlay: '{data.korean_text}' in eye-catching typography"

    result = await generate_image(
        prompt=prompt,
        negative_prompt=data.negative_prompt,
        provider=data.provider,
        size=data.size
    )

    if result.get("success"):
        result["korean_text"] = data.korean_text

    return result

# ============================================
# API Endpoints - M-06 ì—°ë™
# ============================================
@app.post("/api/import/m06-scenes")
async def import_m06_scenes(data: M06SceneImport):
    return {
        "success": True,
        "project_id": data.project_id,
        "title": data.title,
        "scenes": data.scenes,
        "total_scenes": len(data.scenes),
        "thumbnail_suggestions": data.thumbnail_suggestions
    }

# ============================================
# API Endpoints - ì´ë¯¸ì§€ ìƒì„±
# ============================================
class ImageGenerateRequestV2(BaseModel):
    prompt: Optional[str] = None  # í”„ë¡ íŠ¸ì—”ë“œ í˜¸í™˜ìš©
    prompt_en: Optional[str] = None
    negative_prompt: Optional[str] = ""
    provider: str = "dalle3"
    size: str = "1792x1024"
    resolution: Optional[str] = "2k"  # í•´ìƒë„ ì˜µì…˜

@app.post("/api/images/generate")
async def api_generate_image(data: ImageGenerateRequestV2):
    # prompt ë˜ëŠ” prompt_en ì¤‘ í•˜ë‚˜ ì‚¬ìš©
    prompt_text = data.prompt or data.prompt_en
    if not prompt_text:
        return {"success": False, "error": "í”„ë¡¬í”„íŠ¸ê°€ í•„ìš”í•©ë‹ˆë‹¤."}
    
    result = await generate_image(
        prompt=prompt_text,
        negative_prompt=data.negative_prompt or "",
        provider=data.provider,
        size=data.size
    )
    return result

@app.post("/api/images/generate-batch")
async def api_generate_batch(data: BatchGenerateRequest):
    results = []
    for prompt_data in data.prompts:
        result = await generate_image(
            prompt=prompt_data.get("prompt_en", ""),
            negative_prompt=prompt_data.get("negative_prompt", ""),
            provider=data.provider,
            size=prompt_data.get("size", "1792x1024")
        )
        result["scene_id"] = prompt_data.get("scene_id", 0)
        results.append(result)
    
    success_count = sum(1 for r in results if r.get("success"))
    return {
        "success": True,
        "results": results,
        "total": len(data.prompts),
        "success_count": success_count
    }

# ============================================
# n8n Webhook
# ============================================
@app.post("/webhook/image/generate")
async def webhook_generate(data: Dict):
    scenes = data.get("scenes", [])
    designer_id = data.get("designer_id", "bright_cheerful")
    provider = data.get("provider", "dalle3")
    size = data.get("size", "1792x1024")
    
    designer = get_designer(designer_id) or PRESET_DESIGNERS["bright_cheerful"]
    
    results = []
    for scene in scenes:
        prompt_data = build_midjourney_prompt(scene, designer)
        image_result = await generate_image(
            prompt=prompt_data["prompt_en"],
            negative_prompt=prompt_data["negative_prompt"],
            provider=provider,
            size=size
        )
        
        results.append({
            "scene_id": scene.get("scene_id"),
            "prompt": prompt_data["prompt_en"],
            "image_url": image_result.get("image_url"),
            "success": image_result.get("success", False),
            "error": image_result.get("error")
        })
    
    return {
        "success": True,
        "results": results,
        "total": len(scenes),
        "success_count": sum(1 for r in results if r.get("success"))
    }

@app.get("/api/options")
async def get_options():
    return {
        "providers": [
            {"id": "dalle3", "name": "DALL-E 3", "description": "OpenAI - ê³ í’ˆì§ˆ"},
            {"id": "replicate", "name": "Replicate Flux", "description": "ë¹ ë¥´ê³  ì €ë ´"},
            {"id": "replicate-seedream", "name": "SeeDream-4", "description": "ByteDance - ê³ í’ˆì§ˆ"},
            {"id": "replicate-nano-banana", "name": "Nano Banana (Replicate)", "description": "Google ê²½ëŸ‰ ëª¨ë¸"},
            {"id": "replicate-nano-banana-pro", "name": "Nano Banana Pro (Replicate)", "description": "Google ê³ í’ˆì§ˆ ëª¨ë¸"},
            {"id": "vertex", "name": "Vertex AI Imagen", "description": "Google Cloud - ìë™ ì„ íƒ"},
            {"id": "vertex-nano-banana", "name": "Nano Banana (Vertex)", "description": "Google Imagen 4.0 Fast"},
            {"id": "vertex-nano-banana-pro", "name": "Nano Banana Pro (Vertex)", "description": "Google Imagen 4.0 Ultra"}
        ],
        "prompt_ai": [
            {"id": "none", "name": "ì‚¬ìš© ì•ˆí•¨"},
            {"id": "gemini", "name": "Gemini 2.0"},
            {"id": "openai", "name": "GPT-4o"},
            {"id": "gpt4o_mini", "name": "GPT-4o mini"},
            {"id": "claude", "name": "Claude Sonnet"}
        ],
        "sizes": [
            {"id": "1792x1024", "name": "16:9 ê°€ë¡œ", "ratio": "16:9"},
            {"id": "1024x1792", "name": "9:16 ì„¸ë¡œ", "ratio": "9:16"},
            {"id": "1024x1024", "name": "1:1 ì •ì‚¬ê°í˜•", "ratio": "1:1"}
        ],
        "designers": list(PRESET_DESIGNERS.values())
    }

# ============================================
# HTML UI
# ============================================
@app.get("/")
async def root():
    template_path = TEMPLATES_DIR / "index.html"
    if template_path.exists():
        return FileResponse(template_path, media_type="text/html")
    else:
        return HTMLResponse("<html><body><h1>Template not found</h1></body></html>")

if __name__ == "__main__":
    import uvicorn
    print("AI Image Generator v2.6 Server (Port: 8004)")
    uvicorn.run(app, host="0.0.0.0", port=8004)
